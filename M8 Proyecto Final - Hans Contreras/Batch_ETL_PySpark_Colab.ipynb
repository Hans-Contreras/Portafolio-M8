{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "34751337",
      "metadata": {
        "id": "34751337"
      },
      "source": [
        "# üè• M√≥dulo 8 ‚Äì Batch ETL con PySpark (Google Colab)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49751105",
      "metadata": {
        "id": "49751105"
      },
      "source": [
        "## 1) Instalar y configurar Spark en Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0520f63d",
      "metadata": {
        "id": "0520f63d"
      },
      "outputs": [],
      "source": [
        "!apt-get install -qq openjdk-11-jdk > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.7/spark-3.5.7-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.7-bin-hadoop3.tgz\n",
        "!pip -q install pyspark findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "052c767e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "052c767e",
        "outputId": "7025a9f6-3b52-48a4-99c1-d7892e0a6464"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JAVA_HOME = /usr/lib/jvm/java-11-openjdk-amd64\n",
            "SPARK_HOME = /content/spark-3.5.7-bin-hadoop3\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['JAVA_HOME']='/usr/lib/jvm/java-11-openjdk-amd64'\n",
        "os.environ['SPARK_HOME']='/content/spark-3.5.7-bin-hadoop3'\n",
        "print('JAVA_HOME =', os.environ['JAVA_HOME'])\n",
        "print('SPARK_HOME =', os.environ['SPARK_HOME'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c9480d61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9480d61",
        "outputId": "10d61a38-f8eb-49fd-bd79-7b2d981168c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Spark version: 3.5.7\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Mod8-Batch-ETL').getOrCreate()\n",
        "print('‚úÖ Spark version:', spark.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adb0aec2",
      "metadata": {
        "id": "adb0aec2"
      },
      "source": [
        "## 2) Cargar CSV hospitalario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3e2c3989",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e2c3989",
        "outputId": "fef187fb-3a73-4b2e-f3f9-4787bab277eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filas: 280\n",
            "root\n",
            " |-- paciente_id: integer (nullable = true)\n",
            " |-- nombre: string (nullable = true)\n",
            " |-- apellido: string (nullable = true)\n",
            " |-- edad: integer (nullable = true)\n",
            " |-- sexo: string (nullable = true)\n",
            " |-- comuna: string (nullable = true)\n",
            " |-- servicio_clinico: string (nullable = true)\n",
            " |-- fecha_ingreso: date (nullable = true)\n",
            " |-- diagnostico_principal: string (nullable = true)\n",
            " |-- dias_hospitalizacion: integer (nullable = true)\n",
            " |-- costo_total: integer (nullable = true)\n",
            " |-- medico_tratante: string (nullable = true)\n",
            " |-- estado_alta: string (nullable = true)\n",
            "\n",
            "+-----------+------+--------+----+----+-----------+----------------+-------------+-------------------------+--------------------+-----------+---------------+-----------+\n",
            "|paciente_id|nombre|apellido|edad|sexo|comuna     |servicio_clinico|fecha_ingreso|diagnostico_principal    |dias_hospitalizacion|costo_total|medico_tratante|estado_alta|\n",
            "+-----------+------+--------+----+----+-----------+----------------+-------------+-------------------------+--------------------+-----------+---------------+-----------+\n",
            "|1          |Mar√≠a |Gonz√°lez|45  |F   |Santiago   |Medicina Interna|2024-01-15   |Hipertensi√≥n arterial    |3                   |450000     |Dr. Rodr√≠guez  |Alta m√©dica|\n",
            "|2          |Juan  |P√©rez   |67  |M   |Providencia|Cardiolog√≠a     |2024-01-18   |Infarto agudo miocardio  |7                   |1200000    |Dr. Silva      |Alta m√©dica|\n",
            "|3          |Carmen|L√≥pez   |34  |F   |Las Condes |Ginecolog√≠a     |2024-01-20   |Parto normal             |2                   |350000     |Dra. Morales   |Alta m√©dica|\n",
            "|4          |Pedro |Mart√≠nez|78  |M   |√ëu√±oa      |Neurolog√≠a      |2024-01-22   |Accidente cerebrovascular|12                  |2100000    |Dr. Torres     |Alta m√©dica|\n",
            "|5          |Ana   |Jim√©nez |29  |F   |La Reina   |Traumatolog√≠a   |2024-01-25   |Fractura de tibia        |5                   |800000     |Dr. Vargas     |Alta m√©dica|\n",
            "+-----------+------+--------+----+----+-----------+----------------+-------------+-------------------------+--------------------+-----------+---------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "HOSPITAL_CSV = '/content/hospital_santiago_280.csv'\n",
        "df = spark.read.csv(HOSPITAL_CSV, header=True, inferSchema=True)\n",
        "print('Filas:', df.count())\n",
        "df.printSchema()\n",
        "df.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "822a72fe",
      "metadata": {
        "id": "822a72fe"
      },
      "source": [
        "## 3) Limpieza y transformaci√≥n (b√°sica)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8e8e9bbf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e8e9bbf",
        "outputId": "01b509ee-1cbf-4b35-cfcd-1807eb9b66e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Limpieza b√°sica completa\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "NUM_TYPES={'int','bigint','double','float','long'}\n",
        "df = df.toDF(*[c.strip().lower().replace(' ','_') for c in df.columns])\n",
        "df = df.dropDuplicates()\n",
        "num_cols=[c for (c,t) in df.dtypes if t in NUM_TYPES]\n",
        "cat_cols=[c for (c,t) in df.dtypes if t not in NUM_TYPES]\n",
        "for c in num_cols: df = df.na.fill({c:0})\n",
        "for c in cat_cols: df = df.na.fill({c:'desconocido'})\n",
        "print('‚úÖ Limpieza b√°sica completa')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c034cfb",
      "metadata": {
        "id": "4c034cfb"
      },
      "source": [
        "## 4) Consultas SQL (ejemplos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ebccb74b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebccb74b",
        "outputId": "65245e43-7aa9-4874-da02-6e30ca5477d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+-----+\n",
            "|diagnostico_principal|total|\n",
            "+---------------------+-----+\n",
            "|  Enfermedad de Crohn|    2|\n",
            "| Hepatitis autoinmune|    2|\n",
            "|  Artritis reumatoide|    2|\n",
            "| Insuficiencia car...|    2|\n",
            "|    Lupus eritematoso|    2|\n",
            "| S√≠ndrome ovario p...|    2|\n",
            "|  S√≠ndrome de Sj√∂gren|    2|\n",
            "| S√≠ndrome de Goodp...|    2|\n",
            "| Esclerosis sist√©mica|    1|\n",
            "|    Fractura de radio|    1|\n",
            "+---------------------+-----+\n",
            "\n",
            "+-----------------+-----------------+\n",
            "| servicio_clinico|estancia_promedio|\n",
            "+-----------------+-----------------+\n",
            "|        Oncolog√≠a|            16.13|\n",
            "|       Neurolog√≠a|            11.03|\n",
            "|      Cardiolog√≠a|            10.09|\n",
            "|Gastroenterolog√≠a|             9.64|\n",
            "|    Traumatolog√≠a|             7.34|\n",
            "|         Urolog√≠a|             7.17|\n",
            "| Medicina Interna|              7.1|\n",
            "|      Ginecolog√≠a|             4.68|\n",
            "|     Dermatolog√≠a|             4.48|\n",
            "+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.createOrReplaceTempView('hospital')\n",
        "try:\n",
        "    spark.sql('SELECT diagnostico_principal, COUNT(*) AS total FROM hospital GROUP BY diagnostico_principal ORDER BY total DESC LIMIT 10').show()\n",
        "except Exception as e:\n",
        "    print('Ajusta columna diagnostico_principal. Error:', e)\n",
        "try:\n",
        "    spark.sql('SELECT servicio_clinico, ROUND(AVG(dias_hospitalizacion),2) AS estancia_promedio FROM hospital GROUP BY servicio_clinico ORDER BY estancia_promedio DESC').show()\n",
        "except Exception as e:\n",
        "    print('Ajusta servicio_clinico/dias_hospitalizacion. Error:', e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23d582fd",
      "metadata": {
        "id": "23d582fd"
      },
      "source": [
        "## 5) Regresi√≥n simple (MLlib)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dd2daa5e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd2daa5e",
        "outputId": "5d2700be-34c2-453b-9b45-e23411d1809e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 2.5829 | R2: 0.7439\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "label_col='dias_hospitalizacion'\n",
        "feature_exclude={label_col, 'fecha_ingreso'}\n",
        "num_cols=[c for (c,t) in df.dtypes if t in NUM_TYPES and c not in feature_exclude]\n",
        "cat_cols=[c for (c,t) in df.dtypes if t not in NUM_TYPES and c not in feature_exclude]\n",
        "indexers=[StringIndexer(inputCol=c, outputCol=f'{c}_idx', handleInvalid='keep') for c in cat_cols]\n",
        "encoder=OneHotEncoder(inputCols=[f'{c}_idx' for c in cat_cols], outputCols=[f'{c}_ohe' for c in cat_cols], handleInvalid='keep')\n",
        "assembler=VectorAssembler(inputCols=num_cols+[f'{c}_ohe' for c in cat_cols], outputCol='features_raw')\n",
        "scaler=StandardScaler(inputCol='features_raw', outputCol='features')\n",
        "lr=LinearRegression(featuresCol='features', labelCol=label_col)\n",
        "pipe=Pipeline(stages=indexers+[encoder,assembler,scaler,lr])\n",
        "train,test=df.dropna(subset=[label_col]).randomSplit([0.8,0.2],seed=42)\n",
        "model=pipe.fit(train)\n",
        "pred=model.transform(test)\n",
        "ev1=RegressionEvaluator(labelCol=label_col, predictionCol='prediction', metricName='rmse')\n",
        "ev2=RegressionEvaluator(labelCol=label_col, predictionCol='prediction', metricName='r2')\n",
        "print('RMSE:', round(ev1.evaluate(pred),4),'| R2:', round(ev2.evaluate(pred),4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9e74110",
      "metadata": {
        "id": "f9e74110"
      },
      "source": [
        "## 6) Guardar artefactos y modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "66002487",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66002487",
        "outputId": "62954c08-1943-4dc8-c0a5-6d28e154481a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Guardados artefactos y modelo\n"
          ]
        }
      ],
      "source": [
        "import json, os\n",
        "os.makedirs('/content/artifacts', exist_ok=True)\n",
        "os.makedirs('/content/models', exist_ok=True)\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "ev_rmse=RegressionEvaluator(labelCol='dias_hospitalizacion', predictionCol='prediction', metricName='rmse').evaluate(pred)\n",
        "ev_r2=RegressionEvaluator(labelCol='dias_hospitalizacion', predictionCol='prediction', metricName='r2').evaluate(pred)\n",
        "with open('/content/artifacts/batch_reg_metrics.json','w') as f:\n",
        "    json.dump({'rmse': float(ev_rmse), 'r2': float(ev_r2)}, f, indent=2)\n",
        "model.write().overwrite().save('/content/models/batch_lr_model')\n",
        "print('‚úÖ Guardados artefactos y modelo')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}